{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th \n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from model import Generator, Discriminator, gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Import Data\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "# Optimizer params\n",
    "g_lr = 0.001 \n",
    "d_lr = 0.001\n",
    "b1 = 0.5 \n",
    "b2 = 0.999  \n",
    "\n",
    "# WGAN params\n",
    "N_critic = 5            # nr of times to train discriminator more\n",
    "lambda_gp = 10          # gradient penalty hyperpraram\n",
    "\n",
    "# Training params\n",
    "MAX_EPOCHS = 500\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Model Definitions\n",
    "\"\"\"\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = th.optim.Adam(generator.parameters(), lr=g_lr, betas=(b1, b2)) \n",
    "optimizer_D = th.optim.Adam(discriminator.parameters(), lr=d_lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "def train(generator, discriminator, optimizer_g, optimizer_d, data_loader):\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        # real == batch (confusing naming I know...)\n",
    "        for real in data_loader:\n",
    "            # Create new data object with noise and same edge_index \n",
    "            for i in range(N_critic):\n",
    "                noise_batch = []\n",
    "\n",
    "                # Create n_batch number of noise_vectors and batch it\n",
    "                # We must create a noise vector with the corresponding graph in the actual data\n",
    "                for batch_data in real:\n",
    "                    noise = th.randn(batch_data.x.shape)\n",
    "                    noise = Data(x=noise, edge_index=batch_data.edge_indices)\n",
    "                    noise_batch.append(noise)\n",
    "\n",
    "                noise_batch = Batch.from_data_list(noise_batch)\n",
    "\n",
    "                # Input noise_data into generator\n",
    "                global fake \n",
    "                fake = Generator(noise_batch)\n",
    "\n",
    "                # Generator output is a tensor of dimensionality: (sum of all nodes in batch, output_features)\n",
    "                # We must turn this into appropriate (batch) input for the discriminator\n",
    "                splits = [batch_data.shape[0] for batch_data in real]       # nr of nodes per graph\n",
    "                fake_batch = th.split(fake, splits, dim=0)                  # split stacked tensor fake into appropriate batches\n",
    "                fake = Batch.from_data_list(fake_batch)\n",
    "\n",
    "                discriminator_fake = discriminator(fake).reshape(-1)        # discriminator scores for fakes\n",
    "                discriminator_real = discriminator(real).reshape(-1)        # discriminator scores for reals\n",
    "                gp = gradient_penalty(discriminator, real, fake)\n",
    "\n",
    "                # Discriminator loss and train\n",
    "                loss_discriminator = -(th.mean(discriminator_real) - th.mean(discriminator_fake)) + lambda_gp * gp\n",
    "                discriminator.zero_grad() \n",
    "                loss_discriminator.backward() \n",
    "                optimizer_d.step()\n",
    "\n",
    "            # Generator loss and train\n",
    "            output = discriminator(fake).reshape(-1)        # discriminator scores for fake\n",
    "            loss_generator = -th.mean(output)               # loss for genereator = the discriminators' judgement\n",
    "                                                            # higher score = better\n",
    "            generator.zero_grad()\n",
    "            loss_generator.backward()\n",
    "            optimizer_g.step()\n",
    "    \n",
    "        # TODO: Evaluation and logging code??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([7, 1])\n",
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Code for testing dimensionality of batches\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import TAGConv\n",
    "\n",
    "class SomeModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.layer = TAGConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.layer(data.x, data.edge_index)\n",
    "        return x  \n",
    "\n",
    "\n",
    "# Create individual graphs with different number of nodes\n",
    "graph1 = Data(x=torch.randn(5, 16), edge_index=torch.tensor([[0, 1, 2, 3, 4], [1, 2, 3, 4, 0]]), y=torch.randn(5, 1))\n",
    "graph2 = Data(x=torch.randn(7, 16), edge_index=torch.tensor([[0, 1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6, 0]]), y=torch.randn(7, 1))\n",
    "graph3 = Data(x=torch.randn(8, 16), edge_index=torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7, 0]]), y=torch.randn(8, 1))\n",
    "\n",
    "# Create a batch of graphs\n",
    "batch_data = Batch.from_data_list([graph1, graph2, graph3])\n",
    "\n",
    "# Initialize and forward pass through the model\n",
    "model = SomeModel(in_channels=16, out_channels=1)\n",
    "output = model(batch_data)\n",
    "\n",
    "# print(output)\n",
    "print(output.shape)  # Shape of the output tensor\n",
    "\n",
    "new_output = torch.split(output, [5, 7, 8], dim=0)\n",
    "# print(new_output)\n",
    "\n",
    "for tens in new_output:\n",
    "    print(tens.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_ml_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
